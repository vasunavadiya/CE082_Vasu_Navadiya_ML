{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"1-linear-regression.ipynb","provenance":[{"file_id":"10nwF1fxJXltOQIsrHiZYE4ZwmVYRGGyU","timestamp":1630611441238}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"9b80e658"},"source":["import numpy as np\n","import torch"],"id":"9b80e658","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9fc82e14"},"source":["A tensor is a number, vector, matrix or any n-dimensional array."],"id":"9fc82e14"},{"cell_type":"markdown","metadata":{"id":"55824f82"},"source":["## Problem Statement"],"id":"55824f82"},{"cell_type":"markdown","metadata":{"id":"23132f63"},"source":["We'll create a model that predicts crop yeilds for apples (*target variable*) by looking at the average temperature, rainfall and humidity (*input variables or features*) in different regions. \n","\n","Here's the training data:\n","\n",">Temp | Rain | Humidity | Prediction\n",">--- | --- | --- | ---\n","> 73 | 67 | 43 | 56\n","> 91 | 88 | 64 | 81\n","> 87 | 134 | 58 | 119\n","> 102 | 43 | 37 | 22\n","> 69 | 96 | 70 | 103\n","\n","In a **linear regression** model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n","\n","\n","yeild_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n","\n","\n","It means that the yield of apples is a linear or planar function of the temperature, rainfall & humidity.\n","\n","\n","\n","**Our objective**: Find a suitable set of *weights* and *biases* using the training data, to make accurate predictions."],"id":"23132f63"},{"cell_type":"markdown","metadata":{"id":"c3dfbc16"},"source":["## Training Data\n","The training data can be represented using 2 matrices (inputs and targets), each with one row per observation and one column for variable."],"id":"c3dfbc16"},{"cell_type":"code","metadata":{"id":"5889f21b"},"source":["\n","# Input (temp, rainfall, humidity)\n","inputs = np.array([[73, 67, 43], \n","                   [91, 88, 64], \n","                   [87, 134, 58], \n","                   [102, 43, 37], \n","                   [69, 96, 70]], dtype='float32')\n","\n","# Target (apples)\n","targets = np.array([[56], \n","                    [81], \n","                    [119], \n","                    [22], \n","                    [103]], dtype='float32')"],"id":"5889f21b","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"549a7607"},"source":["Before we build a model, we need to convert inputs and targets to PyTorch tensors.\n","\n"],"id":"549a7607"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7d230b9","executionInfo":{"status":"ok","timestamp":1630611387071,"user_tz":-330,"elapsed":1610,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"07e5cf58-f6ed-426c-ce41-650510a5a1a4"},"source":["# Convert inputs and targets to tensors\n","tensor_inputs = torch.tensor(inputs)\n","print(\"tensor inputs:\\n\",tensor_inputs)\n","\n","tensor_targets = torch.tensor(targets)\n","print(\"\\ntensor targets:\\n\",tensor_targets)"],"id":"d7d230b9","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor inputs:\n"," tensor([[ 73.,  67.,  43.],\n","        [ 91.,  88.,  64.],\n","        [ 87., 134.,  58.],\n","        [102.,  43.,  37.],\n","        [ 69.,  96.,  70.]])\n","\n","tensor targets:\n"," tensor([[ 56.],\n","        [ 81.],\n","        [119.],\n","        [ 22.],\n","        [103.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"080dd13b"},"source":["## Linear Regression Model (from scratch)\n","\n","The *weights* and *biases* can also be represented as matrices, initialized with random values. The first row of `w` and the first element of `b` are use to predict the first target variable i.e. yield for apples, and similarly the second for oranges."],"id":"080dd13b"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0d61afd3","executionInfo":{"status":"ok","timestamp":1630611387072,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"d6316d48-8ff2-49c6-d9f4-415e34412b77"},"source":["# Weights and biases\n","weights = torch.randn(1, 3, requires_grad=True)\n","biases = torch.randn(1, requires_grad=True)\n","weights_transpose = torch.transpose(weights, 0, 1)\n","\n","print(\"Weights:\\n\",weights)\n","print(\"\\nBiases:\\n\",biases)\n","print(\"\\nweights_transpose:\\n\",weights_transpose)"],"id":"0d61afd3","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Weights:\n"," tensor([[ 0.5181, -2.0820,  0.4208]], requires_grad=True)\n","\n","Biases:\n"," tensor([0.5507], requires_grad=True)\n","\n","weights_transpose:\n"," tensor([[ 0.5181],\n","        [-2.0820],\n","        [ 0.4208]], grad_fn=<TransposeBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"0075a625"},"source":["The *model* is simply a function that performs a matrix multiplication of the input `x` and the weights `w` (transposed) and adds the bias `b` (replicated for each observation).\n","\n","$$\n","\\hspace{2.5cm} X \\hspace{1.1cm} \\times \\hspace{1.2cm} W^T \\hspace{1.2cm}  + \\hspace{1cm} b \\hspace{2cm}\n","$$\n","\n","$$\n","\\left[ \\begin{array}{cc}\n","73 & 67 & 43 \\\\\n","91 & 88 & 64 \\\\\n","\\vdots & \\vdots & \\vdots \\\\\n","69 & 96 & 70\n","\\end{array} \\right]\n","%\n","\\times\n","%\n","\\left[ \\begin{array}{cc}\n","w_{11} & w_{21} \\\\\n","w_{12} & w_{22} \\\\\n","w_{13} & w_{23}\n","\\end{array} \\right]\n","%\n","+\n","%\n","\\left[ \\begin{array}{cc}\n","b_{1} & b_{2} \\\\\n","b_{1} & b_{2} \\\\\n","\\vdots & \\vdots \\\\\n","b_{1} & b_{2} \\\\\n","\\end{array} \\right]\n","$$"],"id":"0075a625"},{"cell_type":"code","metadata":{"id":"bdde492f"},"source":["# Define the model\n","def fit(X, W_t, b): \n","    return (X @ W_t) + b"],"id":"bdde492f","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"19a6d521"},"source":["The matrix obtained by passing the input data to the model is a set of predictions for the target variables."],"id":"19a6d521"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24cde1ad","executionInfo":{"status":"ok","timestamp":1630611395854,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"20ba0fbb-dd16-4274-8f92-48e2e738d74d"},"source":["\n","# Generate predictions\n","prediction = fit(tensor_inputs, weights_transpose, biases)\n","print(prediction)"],"id":"24cde1ad","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ -83.0212],\n","        [-108.5785],\n","        [-208.9459],\n","        [ -20.5536],\n","        [-134.1080]], grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"978386f2","executionInfo":{"status":"ok","timestamp":1630611397427,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"b8ab8fce-cf10-47d0-cb6b-ee156ac2b909"},"source":["# Compare with targets\n","print(tensor_targets)\n"],"id":"978386f2","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 56.],\n","        [ 81.],\n","        [119.],\n","        [ 22.],\n","        [103.]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"0c28ea58"},"source":["Because we've started with random weights and biases, the model does not perform a good job of predicting the target varaibles."],"id":"0c28ea58"},{"cell_type":"markdown","metadata":{"id":"a947a86c"},"source":["## Loss Function\n","\n","We can compare the predictions with the actual targets, using the following method: \n","* Calculate the difference between the two matrices (`preds` and `targets`).\n","* Square all elements of the difference matrix to remove negative values.\n","* Calculate the average of the elements in the resulting matrix.\n","\n","The result is a single number, known as the **mean squared error** (MSE)."],"id":"a947a86c"},{"cell_type":"code","metadata":{"id":"fce0fa88"},"source":["# MSE loss\n","# help(torch.numel)\n","def mse_loss(pred, target):\n","    temp = pred - target\n","    return torch.sum(temp * temp) / temp.numel()"],"id":"fce0fa88","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"29b52333","executionInfo":{"status":"ok","timestamp":1630611400921,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"2854b3d3-742c-457f-c60f-78ef9026d006"},"source":["# Compute loss\n","loss = mse_loss(prediction, tensor_targets)\n","print(\"Loss: \", loss)\n"],"id":"29b52333","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss:  tensor(44169.2891, grad_fn=<DivBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"fa725b49"},"source":["The resulting number is called the **loss**, because it indicates how bad the model is at predicting the target variables. Lower the loss, better the model. "],"id":"fa725b49"},{"cell_type":"markdown","metadata":{"id":"9e6aeda3"},"source":["## Compute Gradients\n","\n","With PyTorch, we can automatically compute the gradient or derivative of the `loss` w.r.t. to the weights and biases, because they have `requires_grad` set to `True`.\n","\n","More on autograd:  https://pytorch.org/docs/stable/autograd.html#module-torch.autograd"],"id":"9e6aeda3"},{"cell_type":"code","metadata":{"id":"dbc473c1"},"source":["# Compute gradients\n","loss.backward()"],"id":"dbc473c1","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2df7dfbb"},"source":["The gradients are stored in the `.grad` property of the respective tensors."],"id":"2df7dfbb"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8679a2fc","executionInfo":{"status":"ok","timestamp":1630611404889,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"914ce64f-7c4b-4d75-9cb1-83daaa0cfd3e"},"source":["# Gradients for weights\n","print(weights, end=\"\\n-------------\\n\")\n","print(weights.grad)"],"id":"8679a2fc","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.5181, -2.0820,  0.4208]], requires_grad=True)\n","-------------\n","tensor([[-30652.9629, -37813.7031, -22121.5371]])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fb0e4f5","executionInfo":{"status":"ok","timestamp":1630611406394,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"f4345eb9-c52e-494c-c21b-d54f3422abf3"},"source":["# Gradients for bias\n","print(biases, end=\"\\n-------------\\n\")\n","print(biases.grad)"],"id":"8fb0e4f5","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.5507], requires_grad=True)\n","-------------\n","tensor([-374.4829])\n"]}]},{"cell_type":"markdown","metadata":{"id":"9a1f5257"},"source":["A key insight from calculus is that the gradient indicates the rate of change of the loss, or the slope of the loss function w.r.t. the weights and biases. \n","\n","* If a gradient element is **postive**, \n","    * **increasing** the element's value slightly will **increase** the loss.\n","    * **decreasing** the element's value slightly will **decrease** the loss.\n","\n","\n","\n","\n","* If a gradient element is **negative**,\n","    * **increasing** the element's value slightly will **decrease** the loss.\n","    * **decreasing** the element's value slightly will **increase** the loss.\n","    \n","\n","\n","The increase or decrease is proportional to the value of the gradient."],"id":"9a1f5257"},{"cell_type":"markdown","metadata":{"id":"deb55abd"},"source":["Finally, we'll reset the gradients to zero before moving forward, because PyTorch accumulates gradients."],"id":"deb55abd"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ab3e393","executionInfo":{"status":"ok","timestamp":1630611409580,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"e59eee04-718e-4b81-db02-9d06ed44b43e"},"source":["# help(biases.grad.zero_)\n","weights.grad.zero_()\n","biases.grad.zero_()\n","print(weights.grad,end=\"\\n-------\\n\")\n","print(biases.grad)"],"id":"8ab3e393","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0., 0.]])\n","-------\n","tensor([0.])\n"]}]},{"cell_type":"markdown","metadata":{"id":"09fb11b2"},"source":["## Adjust weights and biases using gradient descent\n","​\n","We'll reduce the loss and improve our model using the gradient descent algorithm, which has the following steps:\n","​\n","1. Generate predictions\n","2. Calculate the loss\n","3. Compute gradients w.r.t the weights and biases\n","4. Adjust the weights by subtracting a small quantity proportional to the gradient\n","5. Reset the gradients to zero"],"id":"09fb11b2"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ec4a68a0","executionInfo":{"status":"ok","timestamp":1630611411733,"user_tz":-330,"elapsed":388,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"2ff0bc65-ed40-457c-b323-0d745b7bff2a"},"source":["# Generate predictions\n","prediction = fit(tensor_inputs, weights.t(), biases)\n","print(prediction)"],"id":"ec4a68a0","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ -83.0212],\n","        [-108.5785],\n","        [-208.9459],\n","        [ -20.5536],\n","        [-134.1080]], grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b235c156","executionInfo":{"status":"ok","timestamp":1630611413435,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"8d3b5a92-30ff-4316-fab0-2999b0112dd9"},"source":["# Calculate the loss\n","loss = mse_loss(prediction, tensor_targets)\n","print(loss)"],"id":"b235c156","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(44169.2891, grad_fn=<DivBackward0>)\n"]}]},{"cell_type":"code","metadata":{"id":"931d7252"},"source":["# Compute gradients\n","loss.backward()"],"id":"931d7252","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f12ace7a"},"source":["\n","# Adjust weights & reset gradients\n","with torch.no_grad():\n","    weights -= weights.grad * 1e-5\n","    biases -= biases.grad * 1e-5\n","    weights.grad.zero_()\n","    biases.grad.zero_()"],"id":"f12ace7a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"164409fd","executionInfo":{"status":"ok","timestamp":1630611419280,"user_tz":-330,"elapsed":363,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"a147fe86-2f1f-4d67-9af3-9ea5f57660b1"},"source":["\n","print(weights)"],"id":"164409fd","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.8247, -1.7038,  0.6420]], requires_grad=True)\n"]}]},{"cell_type":"markdown","metadata":{"id":"96b887ee"},"source":["With the new weights and biases, the model should have a lower loss."],"id":"96b887ee"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26bd008c","executionInfo":{"status":"ok","timestamp":1630611420906,"user_tz":-330,"elapsed":8,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"c5359ef4-8317-4b53-fe7d-01238042309b"},"source":["\n","# Calculate loss\n","prediction = fit(tensor_inputs, weights.t(), biases)\n","loss = mse_loss(prediction, tensor_targets)\n","print(loss)"],"id":"26bd008c","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(20680.5488, grad_fn=<DivBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"6a5917b8"},"source":["## Train for multiple epochs\n","\n","To reduce the loss further, we repeat the process of adjusting the weights and biases using the gradients multiple times. Each iteration is called an epoch."],"id":"6a5917b8"},{"cell_type":"code","metadata":{"id":"b5f9b6af"},"source":["# Train for 100 epochs\n","for i in range(100):\n","    prediction = fit(tensor_inputs, weights.t(), biases)\n","    loss = mse_loss(prediction, tensor_targets)\n","    loss.backward()\n","    with torch.no_grad():\n","        weights -= weights.grad * 1e-5\n","        biases -= biases.grad * 1e-5\n","        weights.grad.zero_()\n","        biases.grad.zero_()"],"id":"b5f9b6af","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2409e0d3","executionInfo":{"status":"ok","timestamp":1630611425602,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"0fa14b69-e53c-496d-db36-ea5eee629c8f"},"source":["# Calculate loss\n","prediction = fit(tensor_inputs, weights.t(), biases)\n","loss = mse_loss(prediction, tensor_targets)\n","print(loss)"],"id":"2409e0d3","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(358.2111, grad_fn=<DivBackward0>)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ac533e8","executionInfo":{"status":"ok","timestamp":1630611427381,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"6a7a546a-2c71-432e-e227-3977069b8cba"},"source":["# Print predictions\n","print(prediction)"],"id":"0ac533e8","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[62.5632],\n","        [90.0106],\n","        [92.2686],\n","        [52.3390],\n","        [97.3642]], grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56bf8d03","executionInfo":{"status":"ok","timestamp":1630611429185,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vasu Navadiya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWVuygtK2Sa-vrvrvQGEu24mIeqBYvA7Xv1-Ih2A=s64","userId":"02420649274888470292"}},"outputId":"81eefec0-1622-4f54-91c6-2f4483a4f5c3"},"source":["# Print targets\n","print(tensor_targets)"],"id":"56bf8d03","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 56.],\n","        [ 81.],\n","        [119.],\n","        [ 22.],\n","        [103.]])\n"]}]},{"cell_type":"code","metadata":{"id":"348b41fc"},"source":[""],"id":"348b41fc","execution_count":null,"outputs":[]}]}